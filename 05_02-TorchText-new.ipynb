{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e5ac25-3a38-47dc-a920-cc38c8c4d8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lab preparation: match torch and torchtext versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd9c2e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of Lab: \n",
    "# 1. Input Tutoring Session\n",
    "\n",
    "# 2. Text Preprocessing with TorchText\n",
    "# The text is tokenized \n",
    "# Pretrained GloVe word embeddings loading\n",
    "\n",
    "# 3. Using GPT-2 for Text Generation\n",
    "# A prompt is created that includes the tutoring session and a request\n",
    "# The model generates a response based on the prompt using beam search.\n",
    "# The result is printed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea82b340-43f7-43e5-afca-302b6085d671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# 0. Import libraries\n",
    "# --------------------------\n",
    "import torch\n",
    "from torchtext.vocab import GloVe\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa5b4f2c-7842-41cf-b3a7-59bb9268ed52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# 1. Sample Tutoring Session\n",
    "# --------------------------\n",
    "session_text = \"\"\"\n",
    "Today, we worked on solving quadratic equations using the quadratic formula.\n",
    "The student struggled with identifying the coefficients a, b, and c from the equation format.\n",
    "We practiced several examples and focused on improving accuracy with signs under the square root.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cd68492-66b7-4294-bd1d-fdffa4e80062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session embedding vector shape: torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 2. TorchText Preprocessing\n",
    "# --------------------------\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "tokens = tokenizer(session_text)\n",
    "\n",
    "# Load pretrained GloVe embeddings\n",
    "glove = GloVe(name='6B', dim=100)\n",
    "\n",
    "# Filter to tokens with vectors in vocab\n",
    "token_vectors = [glove[token] for token in tokens if token in glove.stoi]\n",
    "\n",
    "# Combine vectors into a single embedding (e.g., mean-pooling)\n",
    "if token_vectors:\n",
    "    session_embedding = torch.stack(token_vectors).mean(dim=0)\n",
    "else:\n",
    "    session_embedding = torch.zeros(100)  # fallback if empty\n",
    "\n",
    "print(f\"Session embedding vector shape: {session_embedding.shape}\")  # 100-dim vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb85dfc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- GPT-2 Output ---\n",
      "\n",
      "Tutoring session summary:\n",
      "\n",
      "Today, we worked on solving quadratic equations using the quadratic formula.\n",
      "The student struggled with identifying the coefficients a, b, and c from the equation format.\n",
      "We practiced several examples and focused on improving accuracy with signs under the square root.\n",
      "\n",
      "Please suggest exercises to improve understanding of identifying the coefficients for quadratic equations.\n",
      "\n",
      "Summary and question: What is the best way to identify the coefficient for a given equation? What are the most common ways to do this? How can we improve the accuracy of the student's understanding? If you have any questions, please feel free to contact us.\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 3. Use an LLM for Generation\n",
    "# --------------------------\n",
    "llm_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "llm_model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "llm_model.eval()\n",
    "\n",
    "# Add prompt for the model\n",
    "prompt = (\n",
    "    \"Tutoring session summary:\\n\"\n",
    "    f\"{session_text}\\n\"\n",
    "    \"Please suggest exercises to improve understanding of identifying the coefficients for quadratic equations.\\n\" \n",
    "    \"\\n\"\n",
    "    \"Summary and question:\"\n",
    ")\n",
    "\n",
    "# Encode the prompt and generate\n",
    "inputs = llm_tokenizer(prompt, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    outputs = llm_model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=100,\n",
    "        num_beams=5,\n",
    "        no_repeat_ngram_size=2,\n",
    "        early_stopping=True\n",
    "    )\n",
    "\n",
    "generated = llm_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(\"\\n--- GPT-2 Output ---\\n\")\n",
    "print(generated)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
